# üìä Desafio Kaggle ‚Äì Iris Dataset

## Descri√ß√£o do Projeto
Este projeto utiliza o **dataset Iris**, um cl√°ssico da estat√≠stica e do machine learning, contendo medidas de flores de tr√™s esp√©cies: **Setosa, Versicolor e Virginica**.  

O objetivo √© construir uma **an√°lise explorat√≥ria** e **modelos preditivos** capazes de classificar corretamente a esp√©cie da flor com base em suas medidas (comprimento e largura de s√©palas e p√©talas).

---

## Metodologia

1. **Importa√ß√£o dos Dados**  
   - O dataset foi carregado diretamente do GitHub em um DataFrame Pandas.  
   - Foi verificada a integridade dos dados, sem valores nulos ou inconsistentes.  

2. **An√°lise Explorat√≥ria (EDA)**  
   - Distribui√ß√£o das esp√©cies com gr√°ficos de barras interativos usando **Plotly**.  
   - Boxplots para comparar distribui√ß√µes de **comprimento de s√©palas e p√©talas** entre esp√©cies.  
   - **Scatter matrix interativa** para visualizar rela√ß√µes entre todas as medidas, destacando padr√µes e separa√ß√µes entre esp√©cies.  

3. **Prepara√ß√£o dos Dados**  
   - Separa√ß√£o entre **features** (colunas num√©ricas) e **target** (esp√©cie).  
   - Convers√£o da vari√°vel target em n√∫meros usando `LabelEncoder`.  
   - Divis√£o em conjuntos **treino (80%)** e **teste (20%)** mantendo propor√ß√£o das classes (`stratify`).  

4. **Constru√ß√£o de Modelos de Classifica√ß√£o**  
   - Modelos testados: **K-Nearest Neighbors (KNN)**, **Decision Tree** e **Random Forest**.  
   - Avalia√ß√£o via **acur√°cia, relat√≥rio de classifica√ß√£o e matriz de confus√£o**.  

---

## Resultados

### Distribui√ß√£o das Esp√©cies
| Esp√©cie           | Quantidade |
|------------------|------------|
| Iris-setosa       | 50         |
| Iris-versicolor   | 50         |
| Iris-virginica    | 50         |

### Desempenho dos Modelos
| Modelo           | Acur√°cia (Teste) | Observa√ß√µes |
|-----------------|-----------------|-------------|
| K-Nearest Neighbors | 96-97%        | Versicolor √†s vezes confundida com Virginica |
| Decision Tree      | 96-97%        | F√°cil separa√ß√£o da Setosa |
| Random Forest      | 97-100%       | Mais robusto, combina v√°rias √°rvores |

### Dificuldades Observadas
- **Versicolor** apresenta alguma sobreposi√ß√£o com **Virginica**, sendo mais dif√≠cil de classificar.  
- **Setosa** √© facilmente separ√°vel devido √†s diferen√ßas claras nas medidas.

---

## Visualiza√ß√µes Interativas

- **Gr√°fico de Barras:** distribui√ß√£o de esp√©cies  
  ![Barras](link_para_screenshot_barras.png)  

- **Boxplots:** comparativo de medidas de s√©palas e p√©talas  
  ![Boxplots](link_para_screenshot_boxplots.png)  

- **Scatter Matrix:** dispers√£o de todas as medidas  
  ![Scatter Matrix](link_para_screenshot_scatter.png)  

> Substitua os links acima pelos **links gerados no Google Colab** ou imagens exportadas.

---

## Pr√≥ximos Passos

- **Otimiza√ß√£o de hiperpar√¢metros** dos modelos (ex: `n_neighbors`, profundidade das √°rvores).  
- **Feature engineering**: criar novas features, como raz√£o entre comprimento e largura.  
- **Valida√ß√£o cruzada**: para m√©tricas mais confi√°veis.  
- **Testar outros algoritmos**: SVM, Gradient Boosting, redes neurais.  
- **Dashboards interativos** com Plotly Dash ou Streamlit para visualiza√ß√£o din√¢mica do dataset.  

---

## Conclus√£o

Este projeto demonstrou como explorar e modelar dados de forma completa:  
- Atrav√©s da **EDA interativa**, foi poss√≠vel identificar padr√µes claros entre esp√©cies.  
- A **modelagem com m√∫ltiplos algoritmos** mostrou alta acur√°cia, com Random Forest sendo o mais robusto.  
- A documenta√ß√£o e os gr√°ficos podem ser usados diretamente em **portf√≥lio ou apresenta√ß√µes**.


